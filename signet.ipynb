{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0KerA_5dR-H"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F \n",
        "import torch.utils.data as utils \n",
        "import torchvision.transforms as transforms \n",
        "from torch.utils.data import DataLoader \n",
        "import matplotlib.pyplot as plt \n",
        "import torchvision.utils \n",
        "import torchvision \n",
        "from PIL import Image \n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_3XxZ0udfZF"
      },
      "outputs": [],
      "source": [
        "\n",
        "def imshow(img, text=None, should_save=False):\n",
        "    '''This function is used to display images in the form of a grid with text above the grid.'''\n",
        "    npimg = img.numpy()\n",
        "    plt.axis(\"off\")\n",
        "    if text:\n",
        "        plt.text(\n",
        "            75,\n",
        "            8,\n",
        "            text,\n",
        "            style=\"italic\",\n",
        "            fontweight=\"bold\",\n",
        "            bbox={\"facecolor\": \"white\", \"alpha\": 0.8, \"pad\": 10},\n",
        "        )\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def show_plot(iteration, loss):\n",
        "    plt.plot(iteration, loss)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKvdzbKmdgUB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uYhHSq6diqC"
      },
      "outputs": [],
      "source": [
        "class ContrastiveLoss(nn.Module):\n",
        "    \"Contrastive loss function: it aims to learn representations that are similar for the same class and dissimilar for different classes. Usually useful for self-supervised learning.\"\n",
        "\n",
        "    # It calculates the euclidean distance between the two embeddings and then applies a different loss panelty based on the label. If the label is 0, then the loss is calculated as the euclidean distance between the two embeddings. If the label is 1, then the loss is calculated as the maximum between 0 and the difference between the margin and the euclidean distance between the two embeddings. \n",
        "    # The margin is a hyperparameter that is used to define the minimum distance between the two embeddings. If the euclidean distance is greater than the margin, then the loss is 0. If the euclidean distance is less than the margin, then the loss is the difference between the margin and the euclidean distance\n",
        "\n",
        "    def __init__(self, margin=2.0):\n",
        "        super(ContrastiveLoss, self).__init__() # inherit from nn.Module\n",
        "        self.margin = margin # margin is a hyperparameter\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2) # calculate the distance between the two outputs\n",
        "        loss_contrastive = torch.mean(\n",
        "            (1 - label) * torch.pow(euclidean_distance, 2)\n",
        "            + (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
        "        ) # calculate the loss using the contrastive loss function formula \n",
        "        # (1-label) * (euclidean_distance)^2 + (label) * (max(margin - euclidean_distance, 0))^2\n",
        "\n",
        "        return loss_contrastive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Triplet loss will allow our model to map two similar images close and far from dissimilar sample image pairs.\n",
        "# Uses: anchor, positive, negative\n",
        "# Anchor: an image from the dataset\n",
        "# Positive: an image that is similar to the anchor\n",
        "# Negative: an image that is dissimilar to the anchor\n",
        "# Margin increases the separation between our similar and dissimilar vector, and also eliminate the output of any trivial solution.\n",
        "# This similarity or dissimilarity is measured by the distance between two vectors using L2 distance and cosine distance\n",
        "# loss(a,p,n) = max(d(a,p) - d(a,n) + margin, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AAhEIuFyt6u"
      },
      "outputs": [],
      "source": [
        "batch_size = 32 \n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRwErML3dmSL",
        "outputId": "e6246b76-5552-4537-f8ea-356ccbc15a0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3iUNB63r_vb"
      },
      "outputs": [],
      "source": [
        "training_dir = \"/content/gdrive/My Drive/data/sign_data/sign_data/train\"\n",
        "training_csv = \"/content/gdrive/My Drive/data/sign_data/sign_data/train_data.csv\"\n",
        "testing_csv = \"/content/gdrive/My Drive/data/sign_data/sign_data/test_data.csv\"\n",
        "testing_dir = \"/content/gdrive/My Drive/data/sign_data/sign_data/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pros and cons of using a Siamese network:\n",
        "# Pros:\n",
        "# 1. Robustness to class imbalance \n",
        "# 2. Ensemble with one of the classifier algorithms: GBM, RF classifier, SVM, etc.\n",
        "# 3. Semantic Similarity\n",
        "\n",
        "# Cons:\n",
        "# 1. Training time is high\n",
        "# 2. Doesn't output probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Siamese Network\n",
        "\n",
        "# Siamese Network is similarity problem which is used to find the similarity between two comparable things.\n",
        "# Scalable and not much training data is required.\n",
        "# One Shot Classification\n",
        "# The similarity score lies between 0 and 1 using a sigmoid function.\n",
        "\n",
        "# Implementation Procedure:\n",
        "# 1. Training and Validation \n",
        "# 2. Testing\n",
        "# 3. Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training the Network:\n",
        "# The training process of a Siamese network is as follows:\n",
        "\n",
        "# Initialize the siamese network, loss function, and Optimizer(like Adam , Adagrad, SGD etc)\n",
        "# Pass the images one by one out of the image pairs through the siamese network, as here training involves pairwise learning.\n",
        "# Calculate the loss using the outputs from the first and second images using the loss.\n",
        "# Back propagate through the model to calculate the gradients of our model.\n",
        "# Update the weights using an optimizer to minimize the loss after a certain number of epochs\n",
        "# After we reach the max epochs we have set for the model and also get the least loss possible\n",
        "# Save the model\n",
        "\n",
        "\n",
        "# Testing the model:\n",
        "# Load the test data\n",
        "# Pass the image pairs and the labels\n",
        "# Find the euclidean distance between the images\n",
        "# Display the similar image pairs and dissimilar image pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimizers:\n",
        "# 1. SGD: Stochastic Gradient Descent- iteratively updates the model parameters by taking small steps in the direction that decreases the loss. \n",
        "# Advantages: Simplicity, efficiency, robustness\n",
        "# Disadvantages: slow convergence, sensitive to hyperparameters\n",
        "\n",
        "# 2. Adagrad: Adaptive Gradient Algorithm- adapts the learning rate for each parameter based on its historical gradients.\n",
        "# Advantages: Adaptive learning rate, effective for sparse data\n",
        "# Disadvantages: sensitive to early gradients, can over penalize sparse features\n",
        "\n",
        "# 3. RMSprop: Root Mean Square Propagation- uses a moving average of squared gradients to normalize the gradient itself.\n",
        "# Advantages: Less sensitive to early gradients, effective for sparse data\n",
        "# Disadvantages: can still be sensitive to hyperparameters, can over penalize sparse features\n",
        "\n",
        "# 4. Adam: Adaptive Moment Estimation- combines the advantages of RMSprop and Adagrad. It uses an adaptive learning rate and a moving average of the squared gradients, but it also includes a momentum term that helps to speed up convergence.\n",
        "# Advantages: Adaptive learning rate, effective for sparse data, fast convergence\n",
        "# Disadvantages: sensitive to hyperparameters, can be unstable for certain tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "id": "MOJunEuIdqVm",
        "outputId": "aa7e6c8e-1293-45d2-dbd9-4295ad605746"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss0.002057708415065659\n",
            "--------------------\n",
            "Eval loss0.00160527566643082\n",
            "--------------------\n",
            "Best Eval loss0.00160527566643082\n",
            "Model Saved Successfully\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-0b4af7e5a6d8>\u001b[0m in \u001b[0;36m<cell line: 173>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0mbest_eval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9999\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m   \u001b[0meval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-0b4af7e5a6d8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dataloader)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcounter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0miteration_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m       \u001b[0mimg0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m       \u001b[0mimg0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m         \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0mdigest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'md5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mWELCOME\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mAuthenticationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'digest sent was rejected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# load the dataset\n",
        "training_dir = training_dir\n",
        "testing_dir = testing_dir\n",
        "training_csv = training_csv\n",
        "testing_csv = testing_csv\n",
        "\n",
        "\n",
        "# preprocessing and loading the dataset\n",
        "class SiameseDataset:\n",
        "    # Siamise dataset is used to load the dataset and preprocess the images\n",
        "    def __init__(self, training_csv=None, training_dir=None, transform=None):\n",
        "        # used to prepare the labels and images path\n",
        "        self.train_df = pd.read_csv(training_csv)\n",
        "        self.train_df.columns = [\"image1\", \"image2\", \"label\"]\n",
        "        self.train_dir = training_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # getting the image path\n",
        "        image1_path = os.path.join(self.train_dir, self.train_df.iat[index, 0])\n",
        "        image2_path = os.path.join(self.train_dir, self.train_df.iat[index, 1])\n",
        "\n",
        "        # Loading the image\n",
        "        img0 = Image.open(image1_path)\n",
        "        img1 = Image.open(image2_path)\n",
        "        img0 = img0.convert(\"L\")\n",
        "        img1 = img1.convert(\"L\")\n",
        "\n",
        "        # Apply image transformations\n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "\n",
        "        return (\n",
        "            img0,\n",
        "            img1,\n",
        "            torch.from_numpy(\n",
        "                np.array([int(self.train_df.iat[index, 2])], dtype=np.float32)\n",
        "            ),\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.train_df)\n",
        "\n",
        "\n",
        "# Load the the dataset from raw image folders\n",
        "siamese_dataset = SiameseDataset(\n",
        "    training_csv,\n",
        "    training_dir,\n",
        "    transform=transforms.Compose(\n",
        "        [transforms.Resize((105, 105)), transforms.ToTensor()]\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "# Viewing the sample of images and to check whether its loading properly\n",
        "vis_dataloader = DataLoader(siamese_dataset, shuffle=True, batch_size=8) # DataLoader is used to load the data from the dataset and create batches of data\n",
        "dataiter = iter(vis_dataloader) # iter() is used to iterate through all the images in the dataset\n",
        "\n",
        "\n",
        "example_batch = next(dataiter) # next() is used to get the next image in the dataset\n",
        "concatenated = torch.cat((example_batch[0], example_batch[1]), 0) # concatenate the images in the dataset to form a grid of images \n",
        "imshow(torchvision.utils.make_grid(concatenated)) # display the images in the form of a grid\n",
        "print(example_batch[2].numpy()) # print the labels of the images\n",
        "\n",
        "\n",
        "#create a siamese network\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__() # inherit from nn.Module\n",
        "\n",
        "        # Setting up the Sequential of CNN Layers\n",
        "        self.cnn1 = nn.Sequential( # Sequential is used to create a network of layers\n",
        "           \n",
        "            # Convolutional Layer: it is used to extract features from the input image by sliding a filter window over the input image. Every image is then convolved with an image filter.\n",
        "            # Batch Normalization: it is used to normalize the input layer by adjusting and scaling the activations. It also helps in reducing overfitting.    \n",
        "            # Local Response Normalization: it is used to normalize the input layer by adjusting and scaling the activations. It also helps in reducing overfitting.\n",
        "            # ReLU: it is used to add non-linearity to the network.\n",
        "            # Max Pooling: it is used to reduce the size of the image by reducing the information and taking the maximum value pixel from the area of the image covered by the filter.\n",
        "            # Dropout: it is used to prevent overfitting by randomly dropping neurons from the neural network during training.\n",
        "            # Fully Connected Layer: it is used to connect every neuron in one layer to every neuron in another layer.\n",
        "\n",
        "            nn.Conv2d(in_channel=1, out_channel=96, kernel_size=11,stride=1), \n",
        "            nn.BatchNorm2d(num_features=96),\n",
        "            #nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2), \n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channel=96, out_channel=256, kernel_size=5,stride=1,padding=2),\n",
        "            nn.BatchNorm2d(num_features=256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            #nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nn.Dropout(p=0.3),\n",
        "\n",
        "            nn.Conv2d(256,384 , kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(384,256 , kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nn.Dropout(p=0.3),\n",
        "        )\n",
        "\n",
        "        # Defining the fully connected layers\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(30976, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "\n",
        "            nn.Linear(1024, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(128,2))\n",
        "\n",
        "\n",
        "\n",
        "    def forward_once(self, x): \n",
        "        # Forward pass of the neural network \n",
        "        output = self.cnn1(x) # pass the input through the convolutional layers\n",
        "        output = output.view(output.size()[0], -1) # flatten the output from the convolutional layer\n",
        "        output = self.fc1(output) # pass the input through the fully connected layers\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2): \n",
        "        output1 = self.forward_once(input1) # forward pass of input 1\n",
        "        output2 = self.forward_once(input2) # forward pass of input 2\n",
        "        return output1, output2\n",
        "\n",
        " # Load the dataset as pytorch tensors using dataloader\n",
        "\n",
        "train_dataloader = DataLoader(siamese_dataset,\n",
        "                        shuffle=True,\n",
        "                        num_workers=8,\n",
        "                        batch_size=batch_size) \n",
        "\n",
        "\n",
        "net = SiameseNetwork().cuda() # cuda() is used to load the model on the GPU for faster training and testing \n",
        "criterion = ContrastiveLoss() # initialize the contrastive loss function\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, weight_decay=0.0005) # initialize the Adam optimizer\n",
        "\n",
        "# Optimizer: it is used to update the weights of the neural network to minimize the loss function. It uses the gradient of the loss function to update the weights.\n",
        "\n",
        "#train the model\n",
        "def train(train_dataloader):\n",
        "    loss=[] # initialize the loss array\n",
        "    counter=[]\n",
        "    iteration_number = 0\n",
        "    for i, data in enumerate(train_dataloader,0):\n",
        "      img0, img1 , label = data # get the images and labels from the dataloader\n",
        "      img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda() # load the images and labels on the GPU\n",
        "      optimizer.zero_grad() # zero the gradients\n",
        "      output1,output2 = net(img0,img1) # forward pass the images through the network\n",
        "      loss_contrastive = criterion(output1,output2,label) # calculate the loss using the contrastive loss function\n",
        "      loss_contrastive.backward() # backpropagate through the network to calculate the gradients\n",
        "      # backward() generated automatically by autograd \n",
        "      optimizer.step() # update the weights using the optimizer\n",
        "      loss.append(loss_contrastive.item()) # append the loss to the loss array\n",
        "    loss = np.array(loss)\n",
        "    return loss.mean()/len(train_dataloader) # return the mean loss\n",
        "\n",
        "\n",
        "def eval(eval_dataloader):\n",
        "    loss=[]\n",
        "    counter=[]\n",
        "    iteration_number = 0\n",
        "    for i, data in enumerate(eval_dataloader,0):\n",
        "      img0, img1 , label = data\n",
        "      img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
        "      output1,output2 = net(img0,img1)\n",
        "      loss_contrastive = criterion(output1,output2,label)\n",
        "      loss.append(loss_contrastive.item())\n",
        "    loss = np.array(loss)\n",
        "    return loss.mean()/len(eval_dataloader)\n",
        "\n",
        "\n",
        "for epoch in range(1,epochs):\n",
        "  best_eval_loss = 9999 # initialize the best eval loss\n",
        "  train_loss = train(train_dataloader) # train the model on the training dataset\n",
        "  eval_loss = eval(train_dataloader) # evaluate the model on the training dataset\n",
        "\n",
        "  print(f\"Training loss{train_loss}\")\n",
        "  print(\"-\"*20)\n",
        "  print(f\"Eval loss{eval_loss}\")\n",
        "\n",
        "  if eval_loss<best_eval_loss:\n",
        "    best_eval_loss = eval_loss\n",
        "    print(\"-\"*20)\n",
        "    print(f\"Best Eval loss{best_eval_loss}\")\n",
        "    torch.save(net.state_dict(), \"/content/model.pth\")\n",
        "    print(\"Model Saved Successfully\")\n",
        "\n",
        "# Load the test dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okUiYHkcds-B"
      },
      "outputs": [],
      "source": [
        "#create a siamese network\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "\n",
        "        # Setting up the Sequential of CNN Layers\n",
        "        self.cnn1 = nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(1, 96, kernel_size=11,stride=1),\n",
        "            nn.BatchNorm2d(96),\n",
        "            #nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "\n",
        "            nn.Conv2d(96, 256, kernel_size=5,stride=1,padding=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            #nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nn.Dropout(p=0.3),\n",
        "\n",
        "            nn.Conv2d(256,384 , kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(384,256 , kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nn.Dropout(p=0.3),\n",
        "\n",
        "        )\n",
        "\n",
        "        # Defining the fully connected layers\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(30976, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "\n",
        "            nn.Linear(1024, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(128,2))\n",
        "\n",
        "\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        # Forward pass\n",
        "        output = self.cnn1(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc1(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # forward pass of input 1\n",
        "        output1 = self.forward_once(input1)\n",
        "        # forward pass of input 2\n",
        "        output2 = self.forward_once(input2)\n",
        "        return output1, output2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZvgJWoudvj3",
        "outputId": "2b69f6ef-c3c0-438e-cac0-b5ed557522fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SiameseNetwork()\n",
        "model.load_state_dict(torch.load('/content/model.pth'))\n",
        "# model = torch.load('/content/gdrive/MyDrive/data/sign_data/sign_data/model.pt', map_location=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Jg1tG5hNgpl"
      },
      "outputs": [],
      "source": [
        "\n",
        "def compute_accuracy_roc(predictions, labels): \n",
        "    # Compute ROC accuracy with a range of thresholds on distances. \n",
        "    # The ROC curve is a graph that plots the true positive rate (TPR) against the false positive rate (FPR) at all possible classification thresholds. The TPR is the proportion of positive cases that are correctly classified as positive, while the FPR is the proportion of negative cases that are incorrectly classified as positive. \n",
        "    dmax = np.max(predictions) # maximum distance between the two embeddings\n",
        "    dmin = np.min(predictions) # minimum distance between the two embeddings\n",
        "    nsame = np.sum(labels == 1) # number of similar image pairs\n",
        "    ndiff = np.sum(labels == 0) # number of dissimilar image pairs\n",
        "    step = 0.001 # step size\n",
        "    max_acc = 0 # initialize the maximum accuracy\n",
        "\n",
        "    d_optimal = 0 # initialize the optimal distance\n",
        "    for d in np.arange(dmin, dmax + step, step):\n",
        "        idx1 = predictions.ravel() <= d # ravel() is used to flatten the array and idx1 is used to store the indices of the predictions that are less than or equal to d\n",
        "        idx2 = predictions.ravel() > d # idx2 is used to store the indices of the predictions that are greater than d\n",
        "\n",
        "        tpr = float(np.sum(labels[idx1] == 1)) / nsame # true positive rate\n",
        "        tnr = float(np.sum(labels[idx2] == 0)) / ndiff # true negative rate\n",
        "\n",
        "        acc = 0.5 * (tpr + tnr) # accuracy = 0.5 * (true positive rate + true negative rate)\n",
        "\n",
        "        if acc > max_acc:\n",
        "            max_acc = acc # update the maximum accuracy\n",
        "            d_optimal = d # update the optimal distance\n",
        "\n",
        "    return max_acc, d_optimal\n",
        "\n",
        "\n",
        "batch_avg_acc = 0\n",
        "batch_avg_d = 0\n",
        "n_batch = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1E2oCETdzZc",
        "outputId": "0db888c2-d63f-4d6d-a592-ff28e9fdd64f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max accuracy for batch 0 = 0.7 at d = 0.40999777317047126\n",
            "Max accuracy for batch 1 = 0.5 at d = 0.5736076867580416\n",
            "Max accuracy for batch 2 = 0.9166666666666667 at d = 0.9521546574831016\n",
            "Max accuracy for batch 3 = 0.8571428571428572 at d = 0.647489528179169\n",
            "Max accuracy for batch 4 = 0.9166666666666667 at d = 0.6448098766803744\n",
            "Max accuracy for batch 5 = 0.5833333333333334 at d = 0.43232840299606323\n",
            "Max accuracy for batch 6 = 0.7333333333333334 at d = 0.56915846824646\n",
            "Max accuracy for batch 7 = 0.5333333333333333 at d = 0.5206473137140277\n",
            "Max accuracy for batch 8 = 0.75 at d = 0.25693121182918555\n",
            "Max accuracy for batch 9 = 1.0 at d = 0.6742663898468019\n",
            "Max accuracy for batch 10 = 0.5333333333333333 at d = 0.9156227774620057\n",
            "Max accuracy for batch 11 = 0.8333333333333333 at d = 0.5457104467451577\n",
            "Max accuracy for batch 12 = 0.9166666666666667 at d = 0.601152918815613\n",
            "Max accuracy for batch 13 = 0.5333333333333333 at d = 0.4628633325099948\n",
            "Max accuracy for batch 14 = 0.625 at d = 0.24224865436553955\n",
            "Max accuracy for batch 15 = 0.6666666666666666 at d = 0.287508487701416\n",
            "Max accuracy for batch 16 = 0.625 at d = 0.525693434238434\n",
            "Max accuracy for batch 17 = 0.75 at d = 0.6538773384094239\n",
            "Max accuracy for batch 18 = 0.5 at d = 1.3060955629348763\n",
            "Max accuracy for batch 19 = 0.75 at d = 1.0419224601984032\n",
            "Max accuracy for batch 20 = 0.8333333333333333 at d = 0.6210698105096821\n",
            "Max accuracy for batch 21 = 0.6666666666666666 at d = 0.1989225149154663\n",
            "Max accuracy for batch 22 = 0.7 at d = 0.35379900085926075\n",
            "Max accuracy for batch 23 = 0.6 at d = 1.2321739695072185\n",
            "Max accuracy for batch 24 = 0.9 at d = 0.7747910447120671\n",
            "Max accuracy for batch 25 = 1.0 at d = 0.0902424156665802\n",
            "Max accuracy for batch 26 = 0.6666666666666666 at d = 0.8446930496692663\n",
            "Max accuracy for batch 27 = 0.75 at d = 0.4589941656589509\n",
            "Max accuracy for batch 28 = 0.6 at d = 0.16753627359867096\n",
            "Max accuracy for batch 29 = 0.5 at d = 1.1863071584403526\n",
            "Max accuracy for batch 30 = 0.5714285714285714 at d = 0.0677899420261383\n",
            "Max accuracy for batch 31 = 0.625 at d = 0.36518415808677673\n",
            "Max accuracy for batch 32 = 0.75 at d = 0.8955299217700964\n",
            "Max accuracy for batch 33 = 0.625 at d = 0.2106359899044037\n",
            "Max accuracy for batch 34 = 0.625 at d = 0.2929682731628418\n",
            "Max accuracy for batch 35 = 0.625 at d = 0.14478982985019684\n",
            "Max accuracy for batch 36 = 0.8 at d = 0.14929321907460702\n",
            "Max accuracy for batch 37 = 0.875 at d = 0.8437575981616978\n",
            "Max accuracy for batch 38 = 0.8333333333333333 at d = 0.46461609375476864\n",
            "Max accuracy for batch 39 = 0.6 at d = 0.3590838611125946\n",
            "Max accuracy for batch 40 = 0.625 at d = 0.9744075531959537\n",
            "Max accuracy for batch 41 = 0.5333333333333333 at d = 0.6137321510910992\n",
            "Max accuracy for batch 42 = 0.6 at d = 0.2168695479631424\n",
            "Max accuracy for batch 43 = 0.6666666666666666 at d = 0.44329304575920125\n",
            "Max accuracy for batch 44 = 0.6 at d = 0.9043692245483403\n",
            "Max accuracy for batch 45 = 0.75 at d = 0.8864745938777929\n",
            "Max accuracy for batch 46 = 0.5714285714285714 at d = 0.28887784481048584\n",
            "Max accuracy for batch 47 = 0.6333333333333333 at d = 0.5175815854072574\n",
            "Max accuracy for batch 48 = 0.875 at d = 1.0631781554222108\n",
            "Max accuracy for batch 49 = 0.625 at d = 1.3066372494697578\n",
            "Max accuracy for batch 50 = 0.5833333333333334 at d = 1.2831368033885966\n",
            "Max accuracy for batch 51 = 0.6666666666666666 at d = 1.597227566957475\n",
            "Max accuracy for batch 52 = 0.6666666666666666 at d = 0.3381441831588745\n",
            "Max accuracy for batch 53 = 0.8 at d = 0.9346609007120139\n",
            "Max accuracy for batch 54 = 0.75 at d = 0.5629115265011791\n",
            "Max accuracy for batch 55 = 0.7 at d = 0.9260789287090307\n",
            "Max accuracy for batch 56 = 0.6333333333333333 at d = 0.6125146167278294\n",
            "Max accuracy for batch 57 = 0.7 at d = 0.34129652774333963\n",
            "Max accuracy for batch 58 = 0.7 at d = 0.46133426034450553\n",
            "Max accuracy for batch 59 = 0.6666666666666666 at d = 1.2501149354875098\n",
            "Max accuracy for batch 60 = 0.625 at d = 0.4682619045972827\n",
            "Max accuracy for batch 61 = 0.75 at d = 0.32000062847137456\n",
            "Max accuracy for batch 62 = 0.625 at d = 0.2514917254447937\n",
            "Max accuracy for batch 63 = 0.6666666666666666 at d = 0.23408684134483337\n",
            "Max accuracy for batch 64 = 0.9285714285714286 at d = 0.22179935002326967\n",
            "Max accuracy for batch 65 = 0.5 at d = 1.7001130986213693\n",
            "Max accuracy for batch 66 = 0.7857142857142857 at d = 0.6632726068496706\n",
            "Max accuracy for batch 67 = 0.625 at d = 0.9179038696289068\n",
            "Max accuracy for batch 68 = 0.7333333333333334 at d = 0.430669665873051\n",
            "Max accuracy for batch 69 = 0.6666666666666666 at d = 0.49898398447036774\n",
            "Max accuracy for batch 70 = 0.6666666666666666 at d = 1.3117094925642023\n",
            "Max accuracy for batch 71 = 0.5333333333333333 at d = 0.49822131085395827\n",
            "Max accuracy for batch 72 = 0.75 at d = 0.13379740715026855\n",
            "Max accuracy for batch 73 = 0.75 at d = 0.43086883723735836\n",
            "Max accuracy for batch 74 = 0.7333333333333334 at d = 0.34559339964389824\n",
            "Max accuracy for batch 75 = 0.875 at d = 0.5117461271286012\n",
            "Max accuracy for batch 76 = 0.6666666666666666 at d = 0.16381610929965973\n",
            "Max accuracy for batch 77 = 0.625 at d = 1.0113512246608738\n",
            "Max accuracy for batch 78 = 0.6 at d = 0.40498432517051697\n",
            "Max accuracy for batch 79 = 0.8 at d = 0.6376379891633991\n",
            "Max accuracy for batch 80 = 0.5 at d = 1.1716036028265964\n",
            "Max accuracy for batch 81 = 0.5 at d = 0.5210965662002564\n",
            "Max accuracy for batch 82 = 0.6666666666666666 at d = 1.092814291954041\n",
            "Max accuracy for batch 83 = 0.5666666666666667 at d = 0.77352342748642\n",
            "Max accuracy for batch 84 = 0.8571428571428572 at d = 0.5603743857145312\n",
            "Max accuracy for batch 85 = 0.6 at d = 1.1692719637155542\n",
            "Max accuracy for batch 86 = 0.9166666666666667 at d = 0.7507685515880589\n",
            "Max accuracy for batch 87 = 0.6666666666666666 at d = 0.833849801063538\n",
            "Max accuracy for batch 88 = 0.8333333333333333 at d = 0.6651251974105838\n",
            "Max accuracy for batch 89 = 0.625 at d = 0.18183210492134094\n",
            "Max accuracy for batch 90 = 0.75 at d = 0.779087384462357\n",
            "Max accuracy for batch 91 = 0.7333333333333334 at d = 0.6392026621103291\n",
            "Max accuracy for batch 92 = 0.75 at d = 0.5278547343015674\n",
            "Max accuracy for batch 93 = 0.5666666666666667 at d = 0.9406864056587225\n",
            "Max accuracy for batch 94 = 0.6666666666666666 at d = 0.22325925529003143\n",
            "Max accuracy for batch 95 = 0.8 at d = 0.5590480328798298\n",
            "Max accuracy for batch 96 = 0.7333333333333334 at d = 0.3789010905027391\n",
            "Max accuracy for batch 97 = 0.75 at d = 0.7607917306423192\n",
            "Max accuracy for batch 98 = 0.5 at d = 1.5424398770332348\n",
            "Max accuracy for batch 99 = 0.8333333333333333 at d = 0.2963482158184053\n",
            "Max accuracy for batch 100 = 0.625 at d = 0.7598151738643651\n",
            "Max accuracy for batch 101 = 0.625 at d = 0.35323667788505564\n",
            "Max accuracy for batch 102 = 0.7 at d = 0.39925389838218694\n",
            "Max accuracy for batch 103 = 0.6666666666666666 at d = 1.0912112905979163\n",
            "Max accuracy for batch 104 = 0.5333333333333333 at d = 1.066117563962937\n",
            "Max accuracy for batch 105 = 0.625 at d = 0.5948321931362154\n",
            "Max accuracy for batch 106 = 0.625 at d = 0.06578510999679565\n",
            "Max accuracy for batch 107 = 0.6666666666666666 at d = 0.3027648329734802\n",
            "Max accuracy for batch 108 = 0.5666666666666667 at d = 0.7301763720512394\n",
            "Max accuracy for batch 109 = 0.75 at d = 0.35568222355842594\n",
            "Max accuracy for batch 110 = 0.75 at d = 0.12431827932596207\n",
            "Max accuracy for batch 111 = 0.75 at d = 1.0641741180419928\n",
            "Max accuracy for batch 112 = 0.6666666666666666 at d = 0.6416366977691653\n",
            "Max accuracy for batch 113 = 0.7333333333333334 at d = 0.33077322626113914\n",
            "Max accuracy for batch 114 = 0.5 at d = 0.3175301070213319\n",
            "Max accuracy for batch 115 = 0.5833333333333334 at d = 0.33365780115127563\n",
            "Max accuracy for batch 116 = 0.5833333333333334 at d = 1.1645033075883995\n",
            "Max accuracy for batch 117 = 0.75 at d = 0.22846539318561554\n",
            "Max accuracy for batch 118 = 0.7333333333333334 at d = 1.0062812826633458\n",
            "Max accuracy for batch 119 = 0.9285714285714286 at d = 1.0451356000900272\n",
            "Max accuracy for batch 120 = 0.5833333333333334 at d = 1.1172822961807256\n",
            "Max accuracy for batch 121 = 0.7 at d = 1.204063719272614\n",
            "Max accuracy for batch 122 = 0.7 at d = 0.3577295581102373\n",
            "Max accuracy for batch 123 = 0.7 at d = 0.8930717086791997\n",
            "Max accuracy for batch 124 = 0.5 at d = 0.631505592823029\n",
            "Max accuracy for batch 125 = 0.6 at d = 1.1129925944805152\n",
            "Max accuracy for batch 126 = 0.6 at d = 0.9992682582139977\n",
            "Max accuracy for batch 127 = 0.9 at d = 0.6067155486345295\n",
            "Max accuracy for batch 128 = 0.8333333333333333 at d = 0.9240265848636634\n",
            "Max accuracy for batch 129 = 0.6 at d = 1.316713163614274\n",
            "Max accuracy for batch 130 = 0.5833333333333334 at d = 0.05350026488304138\n",
            "Max accuracy for batch 131 = 0.5 at d = 1.058961706280709\n",
            "Max accuracy for batch 132 = 0.75 at d = 0.9063268256187444\n",
            "Max accuracy for batch 133 = 0.6666666666666666 at d = 0.31001710891723633\n",
            "Max accuracy for batch 134 = 0.9 at d = 0.6658304353356367\n",
            "Max accuracy for batch 135 = 0.75 at d = 0.2472473279237748\n",
            "Max accuracy for batch 136 = 0.625 at d = 0.5898467750549319\n",
            "Max accuracy for batch 137 = 0.5 at d = 1.0687568192482\n",
            "Max accuracy for batch 138 = 0.75 at d = 0.7935882682800296\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-96a56c98496f>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  tnr = float(np.sum(labels[idx2] == 0)) / ndiff\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max accuracy for batch 139 = 0 at d = 0\n",
            "Max accuracy for batch 140 = 0.75 at d = 0.5364857937097552\n",
            "Max accuracy for batch 141 = 0.9 at d = 0.4684960517883303\n",
            "Max accuracy for batch 142 = 0.75 at d = 0.38082776916027095\n",
            "Max accuracy for batch 143 = 1.0 at d = 0.9558308377265937\n",
            "Max accuracy for batch 144 = 0.5833333333333334 at d = 0.34587720036506653\n",
            "Max accuracy for batch 145 = 0.8333333333333333 at d = 0.6371776890754702\n",
            "Max accuracy for batch 146 = 0.5 at d = 0.3001952447891236\n",
            "Max accuracy for batch 147 = 0.75 at d = 0.4093502181172374\n",
            "Max accuracy for batch 148 = 0.8333333333333333 at d = 0.43232364976406124\n",
            "Max accuracy for batch 149 = 0.7333333333333334 at d = 1.0775212333202369\n",
            "Max accuracy for batch 150 = 0.9285714285714286 at d = 0.20186934500932707\n",
            "Max accuracy for batch 151 = 0.8333333333333333 at d = 0.705142427682877\n",
            "Max accuracy for batch 152 = 0.5666666666666667 at d = 0.9113524817824371\n",
            "Max accuracy for batch 153 = 0.5 at d = 0.42527846240997336\n",
            "Max accuracy for batch 154 = 0.75 at d = 0.5043079688549044\n",
            "Max accuracy for batch 155 = 0.8333333333333333 at d = 1.0339051684141167\n",
            "Max accuracy for batch 156 = 0.6666666666666666 at d = 0.05475252494215965\n",
            "Max accuracy for batch 157 = 0.7333333333333334 at d = 0.6523449921607973\n",
            "Max accuracy for batch 158 = 0.75 at d = 0.9738781096935278\n",
            "Max accuracy for batch 159 = 0.8 at d = 0.9142799767851837\n",
            "Max accuracy for batch 160 = 0.6666666666666667 at d = 1.0341607842445375\n",
            "Max accuracy for batch 161 = 0.875 at d = 0.6702779018878939\n",
            "Max accuracy for batch 162 = 0.6666666666666667 at d = 0.3972282376289368\n",
            "Max accuracy for batch 163 = 0.5666666666666667 at d = 0.6995213150978092\n",
            "Max accuracy for batch 164 = 0.8333333333333333 at d = 0.6505296535491946\n",
            "Max accuracy for batch 165 = 0.5833333333333334 at d = 1.403100305557252\n",
            "Max accuracy for batch 166 = 0.7 at d = 0.221645968914032\n",
            "Max accuracy for batch 167 = 0.625 at d = 1.3053440696001064\n",
            "Max accuracy for batch 168 = 0.6666666666666666 at d = 0.3350386917591095\n",
            "Max accuracy for batch 169 = 0.6666666666666666 at d = 0.5696876049041748\n",
            "Max accuracy for batch 170 = 0.7333333333333334 at d = 0.9607352385520936\n",
            "Max accuracy for batch 171 = 0.8 at d = 0.27455112743377696\n",
            "Max accuracy for batch 172 = 0.5 at d = 1.1154110279083258\n",
            "Max accuracy for batch 173 = 0.9 at d = 0.87997416484356\n",
            "Max accuracy for batch 174 = 0.5 at d = 1.0709321328401573\n",
            "Max accuracy for batch 175 = 0.7142857142857143 at d = 0.7122035540342335\n",
            "Max accuracy for batch 176 = 0.8 at d = 0.2953844516277315\n",
            "Max accuracy for batch 177 = 0.5 at d = 1.257755040168763\n",
            "Max accuracy for batch 178 = 0.9285714285714286 at d = 0.4375128610134126\n",
            "Max accuracy for batch 179 = 0.8333333333333333 at d = 0.4141593301296237\n",
            "Max accuracy for batch 180 = 0.625 at d = 0.19185186922550201\n",
            "Max accuracy for batch 181 = 0.7333333333333334 at d = 0.8713165688514711\n",
            "Max accuracy for batch 182 = 0.5666666666666667 at d = 0.5661440072059634\n",
            "Max accuracy for batch 183 = 0.75 at d = 0.6665360391139988\n",
            "Max accuracy for batch 184 = 0.75 at d = 0.2973470687866211\n",
            "Max accuracy for batch 185 = 0.9 at d = 0.34369721156358746\n",
            "Max accuracy for batch 186 = 0.6 at d = 0.3200169801712036\n",
            "Max accuracy for batch 187 = 0.75 at d = 0.3953342722654345\n",
            "Max accuracy for batch 188 = 0.5833333333333333 at d = 0.2901828441619875\n",
            "Max accuracy for batch 189 = 0.875 at d = 0.5767486026287082\n",
            "Max accuracy for batch 190 = 0.6428571428571428 at d = 0.14402340185642248\n",
            "Max accuracy for batch 191 = 0.8 at d = 0.8276772789955142\n",
            "Max accuracy for batch 192 = 0.5 at d = 1.0114333806037907\n",
            "Max accuracy for batch 193 = 0.7 at d = 0.6525974779129031\n",
            "Max accuracy for batch 194 = 0.6666666666666667 at d = 1.1924848113060005\n",
            "Max accuracy for batch 195 = 0.5 at d = 0.6555387461185459\n",
            "Max accuracy for batch 196 = 0.5 at d = 1.6280463161468517\n",
            "Max accuracy for batch 197 = 0.75 at d = 0.6063729423284534\n",
            "Max accuracy for batch 198 = 0.6666666666666666 at d = 1.1778909847736367\n",
            "Max accuracy for batch 199 = 0.625 at d = 0.3674231916666032\n",
            "Max accuracy for batch 200 = 0.6666666666666666 at d = 1.2695013362169276\n",
            "Max accuracy for batch 201 = 0.8333333333333333 at d = 0.6912765965461735\n",
            "Max accuracy for batch 202 = 0.9 at d = 0.9321555974483495\n",
            "Max accuracy for batch 203 = 0.5 at d = 1.1100837060511122\n",
            "Max accuracy for batch 204 = 0.5 at d = 0.39486351799964914\n",
            "Max accuracy for batch 205 = 0.7142857142857143 at d = 0.7633403058052067\n",
            "Max accuracy for batch 206 = 0.5 at d = 0.9349449168443686\n",
            "Max accuracy for batch 207 = 0.6333333333333333 at d = 0.6322779247760776\n",
            "Max accuracy for batch 208 = 0.5 at d = 1.2203966827392585\n",
            "Max accuracy for batch 209 = 0.625 at d = 0.4954184591770172\n",
            "Max accuracy for batch 210 = 1.0 at d = 0.678349288642407\n",
            "Max accuracy for batch 211 = 0.6333333333333333 at d = 0.6848889960050587\n",
            "Max accuracy for batch 212 = 0.75 at d = 0.37446005618572253\n",
            "Max accuracy for batch 213 = 0.5 at d = 1.1420790900588045\n",
            "Max accuracy for batch 214 = 0.5 at d = 0.544375228881836\n",
            "Max accuracy for batch 215 = 0.625 at d = 0.26655396819114685\n",
            "Max accuracy for batch 216 = 0.6666666666666666 at d = 1.0984879740476616\n",
            "Max accuracy for batch 217 = 0.7 at d = 0.9192895190715795\n",
            "Max accuracy for batch 218 = 0.7 at d = 0.3905837256908419\n",
            "Max accuracy for batch 219 = 0.5 at d = 0.2571237838268281\n",
            "Max accuracy for batch 220 = 0.9 at d = 0.898213516235352\n",
            "Max accuracy for batch 221 = 0.8333333333333333 at d = 1.0107750270366676\n",
            "Max accuracy for batch 222 = 0.625 at d = 0.21767574548721313\n",
            "Max accuracy for batch 223 = 0.8 at d = 0.42139430887997187\n",
            "Max accuracy for batch 224 = 0.7 at d = 0.604441565036774\n",
            "Max accuracy for batch 225 = 0.7142857142857143 at d = 0.7682727138996129\n",
            "Max accuracy for batch 226 = 0.75 at d = 0.4710333847999575\n",
            "Max accuracy for batch 227 = 0 at d = 0\n",
            "Max accuracy for batch 228 = 0.9 at d = 0.7188321344852452\n",
            "Max accuracy for batch 229 = 0.5714285714285714 at d = 1.1829119102954873\n",
            "Max accuracy for batch 230 = 0.6666666666666667 at d = 1.2068480648994453\n",
            "Max accuracy for batch 231 = 0.5 at d = 1.270454033613206\n",
            "Max accuracy for batch 232 = 0.75 at d = 0.34649461531639103\n",
            "Max accuracy for batch 233 = 0.75 at d = 1.0683418084383018\n",
            "Max accuracy for batch 234 = 0.6333333333333333 at d = 0.4330789865255358\n",
            "Max accuracy for batch 235 = 0.6666666666666666 at d = 0.9213717434406286\n",
            "Max accuracy for batch 236 = 0.625 at d = 0.22757405638694772\n",
            "Max accuracy for batch 237 = 0.5 at d = 1.6300453155189767\n",
            "Max accuracy for batch 238 = 0.7 at d = 0.43126352691650405\n",
            "Max accuracy for batch 239 = 0.75 at d = 0.3395976871252061\n",
            "Max accuracy for batch 240 = 0.6 at d = 0.931321247577668\n",
            "Max accuracy for batch 241 = 0.8571428571428572 at d = 0.6792245514392856\n",
            "Max accuracy for batch 242 = 0.5666666666666667 at d = 0.5173471813201908\n",
            "Max accuracy for batch 243 = 0.6666666666666666 at d = 0.2157534956932068\n",
            "Max accuracy for batch 244 = 0.5833333333333334 at d = 0.33353570103645325\n",
            "Max accuracy for batch 245 = 0.8333333333333333 at d = 1.0983834695816048\n",
            "Max accuracy for batch 246 = 0.625 at d = 0.9820491594076164\n",
            "Max accuracy for batch 247 = 0.625 at d = 0.029913567006587982\n",
            "Max accuracy for batch 248 = 0.75 at d = 0.9028208836317069\n",
            "Max accuracy for batch 249 = 0.5 at d = 0.4749323816299441\n",
            "Max accuracy for batch 250 = 1.0 at d = 0.19493544101715088\n",
            "Max accuracy for batch 251 = 0.7333333333333334 at d = 0.5378799154758457\n",
            "Max accuracy for batch 252 = 0.6 at d = 0.43552809953689575\n",
            "Max accuracy for batch 253 = 0.625 at d = 0.9718318517208105\n",
            "Max accuracy for batch 254 = 0.5 at d = 0.5205883775949481\n",
            "Max accuracy for batch 255 = 0.5 at d = 0.8162183305025107\n",
            "Max accuracy for batch 256 = 0.5 at d = 1.646553206920625\n",
            "Max accuracy for batch 257 = 0.625 at d = 0.6884732040464884\n",
            "Max accuracy for batch 258 = 0.75 at d = 0.3496967631578447\n",
            "Max accuracy for batch 259 = 0.75 at d = 0.9705079619884498\n",
            "Max accuracy for batch 260 = 0.5833333333333333 at d = 0.9755985189080246\n",
            "Max accuracy for batch 261 = 0.6333333333333333 at d = 0.9073246511220938\n",
            "Max accuracy for batch 262 = 0.5666666666666667 at d = 0.8551043471097952\n",
            "Max accuracy for batch 263 = 0.75 at d = 0.2652725274562836\n",
            "Max accuracy for batch 264 = 0.625 at d = 0.5500921916365628\n",
            "Max accuracy for batch 265 = 0.875 at d = 0.8019395112991338\n",
            "Max accuracy for batch 266 = 0.6 at d = 0.9662572500705726\n",
            "Max accuracy for batch 267 = 0.5 at d = 1.4705982451438913\n",
            "Max accuracy for batch 268 = 0.7857142857142857 at d = 0.9649903120994573\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-96a56c98496f>:14: RuntimeWarning: invalid value encountered in divide\n",
            "  tpr = float(np.sum(labels[idx1] == 1)) / nsame\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max accuracy for batch 269 = 0 at d = 0\n",
            "Max accuracy for batch 270 = 0.5 at d = 0.41391694784164446\n",
            "Max accuracy for batch 271 = 0.5 at d = 1.2455436229705819\n",
            "Max accuracy for batch 272 = 0.6 at d = 0.4054991900920868\n",
            "Max accuracy for batch 273 = 0.8 at d = 0.9958498842716224\n",
            "Max accuracy for batch 274 = 0.7333333333333334 at d = 0.8201560051441198\n",
            "Max accuracy for batch 275 = 0.5833333333333334 at d = 0.26170313358306885\n",
            "Max accuracy for batch 276 = 0.5 at d = 0.6140403032302858\n",
            "Max accuracy for batch 277 = 0.5 at d = 1.5082339587211617\n",
            "Max accuracy for batch 278 = 0.75 at d = 0.7866283900737767\n",
            "Max accuracy for batch 279 = 0.75 at d = 0.32131242752075195\n",
            "Max accuracy for batch 280 = 0.5 at d = 0.9643257906436926\n",
            "Max accuracy for batch 281 = 0.6666666666666666 at d = 0.11357490107417112\n",
            "Max accuracy for batch 282 = 0.7 at d = 0.6773116753101354\n",
            "Max accuracy for batch 283 = 1.0 at d = 0.46899520468711864\n",
            "Max accuracy for batch 284 = 0.6666666666666666 at d = 1.105114307403565\n",
            "Max accuracy for batch 285 = 0.8333333333333333 at d = 0.6344051302671436\n",
            "Max accuracy for batch 286 = 0.625 at d = 0.8777106668949132\n",
            "Max accuracy for batch 287 = 0.6 at d = 0.316297709941864\n",
            "Max accuracy for batch 288 = 0.7 at d = 0.391653388142586\n",
            "Max accuracy for batch 289 = 0.6666666666666666 at d = 0.44124481868743903\n",
            "Max accuracy for batch 290 = 0.5 at d = 0.6978482182025911\n",
            "Max accuracy for batch 291 = 0.75 at d = 0.7062694089710718\n",
            "Max accuracy for batch 292 = 0.6666666666666666 at d = 0.24345149099826813\n",
            "Max accuracy for batch 293 = 0.75 at d = 0.3780779540538788\n",
            "Max accuracy for batch 294 = 0.6 at d = 0.32113802433013916\n",
            "Max accuracy for batch 295 = 0.6666666666666666 at d = 0.36265416324138655\n",
            "Max accuracy for batch 296 = 0.6666666666666666 at d = 1.3063828793764123\n",
            "Max accuracy for batch 297 = 0.5 at d = 0.46798915815353426\n",
            "Max accuracy for batch 298 = 0.875 at d = 0.7414857150316243\n",
            "Max accuracy for batch 299 = 0.75 at d = 0.2664636011123658\n",
            "Max accuracy for batch 300 = 0.625 at d = 0.40449509024620056\n",
            "Max accuracy for batch 301 = 0.9 at d = 0.7011335952281957\n",
            "Max accuracy for batch 302 = 0.5 at d = 1.383940240383149\n",
            "Max accuracy for batch 303 = 0.75 at d = 0.8309419285058981\n",
            "Max accuracy for batch 304 = 0.5 at d = 1.1656715615987787\n",
            "Max accuracy for batch 305 = 0.625 at d = 0.062224771827459335\n",
            "Max accuracy for batch 306 = 0.875 at d = 0.8588804018497472\n",
            "Max accuracy for batch 307 = 0.7 at d = 0.5899867079257969\n",
            "Max accuracy for batch 308 = 0.5 at d = 2.0450324737429635\n",
            "Max accuracy for batch 309 = 0.9285714285714286 at d = 0.8172990738153463\n",
            "Max accuracy for batch 310 = 0.5 at d = 1.2523105988502512\n",
            "Max accuracy for batch 311 = 0.75 at d = 0.08223018795251846\n",
            "Max accuracy for batch 312 = 0.6 at d = 1.4287019562721262\n",
            "Max accuracy for batch 313 = 0.625 at d = 0.19238795340061188\n",
            "Max accuracy for batch 314 = 0.6666666666666666 at d = 1.050634849309922\n",
            "Max accuracy for batch 315 = 0.7 at d = 0.5135625300407411\n",
            "Max accuracy for batch 316 = 0.7 at d = 0.5352267968654636\n",
            "Max accuracy for batch 317 = 0.6666666666666666 at d = 0.9632522459030157\n",
            "Max accuracy for batch 318 = 0.5833333333333334 at d = 0.18101097643375397\n",
            "Max accuracy for batch 319 = 0.75 at d = 0.7718028146028524\n",
            "Max accuracy for batch 320 = 0.75 at d = 0.9643470525741584\n",
            "Max accuracy for batch 321 = 0.5 at d = 1.9785148383378999\n",
            "Max accuracy for batch 322 = 0.75 at d = 0.6696460068225863\n",
            "Max accuracy for batch 323 = 0.5833333333333334 at d = 0.08209472894668579\n",
            "Max accuracy for batch 324 = 0.5 at d = 1.227941856265069\n",
            "Max accuracy for batch 325 = 0.7857142857142857 at d = 0.6268065023422242\n",
            "Max accuracy for batch 326 = 0.625 at d = 0.3290916383266449\n",
            "Max accuracy for batch 327 = 0.625 at d = 0.25298187136650085\n",
            "Max accuracy for batch 328 = 0.5 at d = 0.7086584448814393\n",
            "Max accuracy for batch 329 = 0.5 at d = 0.8636247415542607\n",
            "Max accuracy for batch 330 = 1.0 at d = 0.9171378226280216\n",
            "Max accuracy for batch 331 = 0.7333333333333334 at d = 0.4086557891368867\n",
            "Max accuracy for batch 332 = 0.9166666666666667 at d = 0.7103728274106984\n",
            "Max accuracy for batch 333 = 0.6666666666666666 at d = 0.3903090279102326\n",
            "Max accuracy for batch 334 = 0.8333333333333333 at d = 0.8629126071929935\n",
            "Max accuracy for batch 335 = 0.9 at d = 0.5588976387977602\n",
            "Max accuracy for batch 336 = 0.5 at d = 0.7707018661499028\n",
            "Max accuracy for batch 337 = 0.5 at d = 0.22650595450401312\n",
            "Max accuracy for batch 338 = 0.5 at d = 1.484133943319322\n",
            "Max accuracy for batch 339 = 0.7333333333333334 at d = 0.558385544061661\n",
            "Max accuracy for batch 340 = 0.6333333333333333 at d = 0.4973086898326875\n",
            "Max accuracy for batch 341 = 0.75 at d = 0.9970249962806708\n",
            "Max accuracy for batch 342 = 0.8 at d = 0.8076017680168156\n",
            "Max accuracy for batch 343 = 0.75 at d = 0.7639694414138799\n",
            "Max accuracy for batch 344 = 0.6333333333333333 at d = 0.7012414650917056\n",
            "Max accuracy for batch 345 = 0.875 at d = 0.6275863676071171\n",
            "Max accuracy for batch 346 = 0.5 at d = 1.2606198501586923\n",
            "Max accuracy for batch 347 = 0.5666666666666667 at d = 0.8943115679025657\n",
            "Max accuracy for batch 348 = 0.5 at d = 0.6254833523035054\n",
            "Max accuracy for batch 349 = 0.7333333333333334 at d = 0.666042648017407\n",
            "Max accuracy for batch 350 = 1.0 at d = 0.6239304896593098\n",
            "Max accuracy for batch 351 = 0.6666666666666666 at d = 0.2836991250514984\n",
            "Max accuracy for batch 352 = 0.6 at d = 0.3827301859855652\n",
            "Max accuracy for batch 353 = 0.6666666666666666 at d = 0.27658119797706604\n",
            "Max accuracy for batch 354 = 0.8333333333333333 at d = 0.5307513569593433\n",
            "Max accuracy for batch 355 = 0.5 at d = 1.5376887583732612\n",
            "Max accuracy for batch 356 = 0.625 at d = 0.2270347774028778\n",
            "Max accuracy for batch 357 = 0.6333333333333333 at d = 0.6689343826770786\n",
            "Max accuracy for batch 358 = 0.5 at d = 1.3841764857769023\n",
            "Max accuracy for batch 359 = 0.9285714285714286 at d = 0.855713226795197\n",
            "Max accuracy for batch 360 = 0.9 at d = 0.7359295773506167\n",
            "Max accuracy for batch 361 = 0.5833333333333334 at d = 0.12792396545410156\n",
            "Max accuracy for batch 362 = 0.7 at d = 0.5892123888731007\n",
            "Max accuracy for batch 363 = 0.625 at d = 0.8993191013336185\n",
            "Max accuracy for batch 364 = 0.625 at d = 0.9744863635301597\n",
            "Max accuracy for batch 365 = 0.5 at d = 1.3332113256454474\n",
            "Max accuracy for batch 366 = 0 at d = 0\n",
            "Max accuracy for batch 367 = 0.7333333333333334 at d = 0.5950168354511264\n",
            "Max accuracy for batch 368 = 0.5 at d = 0.8921733753681188\n",
            "Max accuracy for batch 369 = 0.625 at d = 0.5196697607040408\n",
            "Max accuracy for batch 370 = 0.7 at d = 0.40170541203022025\n",
            "Max accuracy for batch 371 = 0.8 at d = 0.7140472276210789\n",
            "Max accuracy for batch 372 = 0.8333333333333333 at d = 0.39177088165283225\n",
            "Max accuracy for batch 373 = 0.6666666666666666 at d = 0.47777233600616464\n",
            "Max accuracy for batch 374 = 0.5 at d = 0.7207362027168275\n",
            "Max accuracy for batch 375 = 0.625 at d = 0.9571808601915844\n",
            "Max accuracy for batch 376 = 0.625 at d = 0.0879586786031723\n",
            "Max accuracy for batch 377 = 0.6666666666666666 at d = 1.0129555662274368\n",
            "Max accuracy for batch 378 = 0.625 at d = 0.6803304427862171\n",
            "Max accuracy for batch 379 = 0.8333333333333333 at d = 0.3224486989974976\n",
            "Max accuracy for batch 380 = 0.6666666666666666 at d = 0.048643890768289566\n",
            "Max accuracy for batch 381 = 0.5 at d = 0.8131101350784304\n",
            "Max accuracy for batch 382 = 0.5 at d = 1.8675485458374035\n",
            "Max accuracy for batch 383 = 0.625 at d = 0.017001384869217873\n",
            "Max accuracy for batch 384 = 0.5 at d = 0.982648027181626\n",
            "Max accuracy for batch 385 = 0.5 at d = 0.41838456034660343\n",
            "Max accuracy for batch 386 = 0.9285714285714286 at d = 0.5808723673820497\n",
            "Max accuracy for batch 387 = 0.75 at d = 1.1420590138435371\n",
            "Max accuracy for batch 388 = 1.0 at d = 0.26414711570739746\n",
            "Max accuracy for batch 389 = 0.5 at d = 0.5000780121088031\n",
            "Max accuracy for batch 390 = 0.5714285714285714 at d = 1.3629029005765925\n",
            "Max accuracy for batch 391 = 0.7333333333333334 at d = 0.845435952663422\n",
            "Max accuracy for batch 392 = 0.75 at d = 0.9525136210918431\n",
            "Max accuracy for batch 393 = 0.5833333333333333 at d = 0.38467207652330426\n",
            "Max accuracy for batch 394 = 0.5 at d = 1.4305804748535165\n",
            "Max accuracy for batch 395 = 0.5 at d = 0.7344488503932957\n",
            "Max accuracy for batch 396 = 0.75 at d = 0.27164415204525005\n",
            "Max accuracy for batch 397 = 0.5 at d = 0.4276096217632295\n",
            "Max accuracy for batch 398 = 0.625 at d = 0.34504958987236023\n",
            "Max accuracy for batch 399 = 0.6 at d = 0.43254536390304565\n",
            "Max accuracy for batch 400 = 0.9166666666666667 at d = 0.7841521782875065\n",
            "Max accuracy for batch 401 = 0.75 at d = 0.1918484997749329\n",
            "Max accuracy for batch 402 = 0.6666666666666666 at d = 0.7322479047775269\n",
            "Max accuracy for batch 403 = 0.625 at d = 1.1970619287490847\n",
            "Max accuracy for batch 404 = 0.5 at d = 1.6151003350615514\n",
            "Max accuracy for batch 405 = 0.7142857142857143 at d = 0.2580081034898759\n",
            "Max accuracy for batch 406 = 0.5 at d = 1.206961390018464\n",
            "Max accuracy for batch 407 = 0.75 at d = 0.5552507624626161\n",
            "Max accuracy for batch 408 = 0.7333333333333334 at d = 0.7606707288026815\n",
            "Max accuracy for batch 409 = 0.7142857142857143 at d = 0.6394563443660738\n",
            "Max accuracy for batch 410 = 0.5 at d = 1.6686673305034647\n",
            "Max accuracy for batch 411 = 0.625 at d = 0.210696280002594\n",
            "Max accuracy for batch 412 = 0.7 at d = 0.5209156034588818\n",
            "Max accuracy for batch 413 = 0.875 at d = 0.7721289365291598\n",
            "Max accuracy for batch 414 = 0.6666666666666666 at d = 0.10406491160392761\n",
            "Max accuracy for batch 415 = 0.625 at d = 0.43225333338975935\n",
            "Max accuracy for batch 416 = 0.625 at d = 0.3674777150154114\n",
            "Max accuracy for batch 417 = 0.7 at d = 0.3713594908714295\n",
            "Max accuracy for batch 418 = 0.625 at d = 0.36178309124708197\n",
            "Max accuracy for batch 419 = 0.5833333333333334 at d = 1.2493242210149775\n",
            "Max accuracy for batch 420 = 0.5 at d = 1.0415327181816105\n",
            "Max accuracy for batch 421 = 0.6666666666666667 at d = 0.9049615468978889\n",
            "Max accuracy for batch 422 = 0.625 at d = 0.3971509039402008\n",
            "Max accuracy for batch 423 = 0.75 at d = 0.48787330937385576\n",
            "Max accuracy for batch 424 = 0.6 at d = 1.0954494721889503\n",
            "Max accuracy for batch 425 = 0.5 at d = 1.2965290678739558\n",
            "Max accuracy for batch 426 = 0.8 at d = 0.6421097292900089\n",
            "Max accuracy for batch 427 = 0.8333333333333333 at d = 0.44326593554019955\n",
            "Max accuracy for batch 428 = 0.75 at d = 0.1720447987318039\n",
            "Max accuracy for batch 429 = 0.5333333333333333 at d = 0.4241568125486376\n",
            "Max accuracy for batch 430 = 0.6 at d = 0.9407077515125282\n",
            "Max accuracy for batch 431 = 0.6 at d = 0.15186254680156708\n",
            "Max accuracy for batch 432 = 0.625 at d = 0.6636950805187227\n",
            "Max accuracy for batch 433 = 0.875 at d = 0.4520236797332765\n",
            "Max accuracy for batch 434 = 0.6 at d = 0.30925625562667847\n",
            "Max accuracy for batch 435 = 0.5666666666666667 at d = 1.2840049853324897\n",
            "Max accuracy for batch 436 = 0.625 at d = 0.7173687093257909\n",
            "Max accuracy for batch 437 = 0.5 at d = 1.4670374369621286\n",
            "Max accuracy for batch 438 = 0.7 at d = 0.5812166922092441\n",
            "Max accuracy for batch 439 = 0.5 at d = 0.5898440361022952\n",
            "Max accuracy for batch 440 = 0.5 at d = 1.6728098810315146\n",
            "Max accuracy for batch 441 = 0.75 at d = 0.3640600185394288\n",
            "Max accuracy for batch 442 = 0.5833333333333334 at d = 1.0492499356269842\n",
            "Max accuracy for batch 443 = 0.75 at d = 0.8432017496526248\n",
            "Max accuracy for batch 444 = 0.8333333333333333 at d = 0.6943232858181003\n",
            "Max accuracy for batch 445 = 0.625 at d = 0.40328800678253174\n",
            "Max accuracy for batch 446 = 0.625 at d = 0.38987672328948975\n",
            "Max accuracy for batch 447 = 0.7142857142857143 at d = 0.7709193792343144\n",
            "Max accuracy for batch 448 = 0.75 at d = 0.4938888822793963\n",
            "Max accuracy for batch 449 = 0.625 at d = 1.2331189820766455\n",
            "Max accuracy for batch 450 = 0.7142857142857143 at d = 0.877084403634072\n",
            "Max accuracy for batch 451 = 0.5 at d = 0.9627977373600013\n",
            "Max accuracy for batch 452 = 0.6666666666666666 at d = 0.01975356973707676\n",
            "Max accuracy for batch 453 = 0.625 at d = 0.37634655833244324\n",
            "Max accuracy for batch 454 = 0.7142857142857143 at d = 0.9997382080554968\n",
            "Max accuracy for batch 455 = 0.5 at d = 0.5777366666793825\n",
            "Max accuracy for batch 456 = 0.7 at d = 1.0285787574052818\n",
            "Max accuracy for batch 457 = 0.7857142857142857 at d = 0.676131749272347\n",
            "Max accuracy for batch 458 = 0.5 at d = 1.9567470605373396\n",
            "Max accuracy for batch 459 = 0.75 at d = 0.2756737352609635\n",
            "Max accuracy for batch 460 = 0.625 at d = 0.2377869188785553\n",
            "Max accuracy for batch 461 = 0.625 at d = 0.23409782350063324\n",
            "Max accuracy for batch 462 = 0.6666666666666667 at d = 0.7609717514514927\n",
            "Max accuracy for batch 463 = 0.7333333333333334 at d = 0.5990307440757754\n",
            "Max accuracy for batch 464 = 0.875 at d = 0.5677031661868099\n",
            "Max accuracy for batch 465 = 0.75 at d = 0.4909309391975404\n",
            "Max accuracy for batch 466 = 0.625 at d = 0.3748875558376312\n",
            "Max accuracy for batch 467 = 0.6666666666666667 at d = 0.3857393333911896\n",
            "Max accuracy for batch 468 = 0.9285714285714286 at d = 0.7870432376861574\n",
            "Max accuracy for batch 469 = 0.5833333333333333 at d = 0.605597741991282\n",
            "Max accuracy for batch 470 = 0.6666666666666666 at d = 0.5308722852468494\n",
            "Max accuracy for batch 471 = 0.8333333333333333 at d = 0.5906656153798108\n",
            "Max accuracy for batch 472 = 0.75 at d = 0.8185215101242069\n",
            "Max accuracy for batch 473 = 0.6666666666666666 at d = 0.842031310677529\n",
            "Max accuracy for batch 474 = 0.6 at d = 0.21838688850402832\n",
            "Max accuracy for batch 475 = 1.0 at d = 1.0048665978908544\n",
            "Max accuracy for batch 476 = 0.5 at d = 0.3380780800580979\n",
            "Max accuracy for batch 477 = 0.5 at d = 1.1076728829741487\n",
            "Max accuracy for batch 478 = 0.8333333333333333 at d = 0.262392106473446\n",
            "Max accuracy for batch 479 = 0.5 at d = 1.1187130901813513\n",
            "Max accuracy for batch 480 = 0.5 at d = 1.402997472524644\n",
            "Max accuracy for batch 481 = 0.625 at d = 1.1899828969240198\n",
            "Max accuracy for batch 482 = 0.5 at d = 0.6840337901115421\n",
            "Max accuracy for batch 483 = 0.6666666666666667 at d = 0.31040922439098373\n",
            "Max accuracy for batch 484 = 0.7333333333333334 at d = 0.7130579669475557\n",
            "Max accuracy for batch 485 = 0.8 at d = 0.43979900109767933\n",
            "Max accuracy for batch 486 = 0.6666666666666666 at d = 0.8448478850126272\n",
            "Max accuracy for batch 487 = 0.6666666666666666 at d = 0.8128761522769933\n",
            "Max accuracy for batch 488 = 0.5 at d = 1.5507310466766369\n",
            "Max accuracy for batch 489 = 0.5 at d = 0.9780281540751465\n",
            "Max accuracy for batch 490 = 0.625 at d = 0.30413883924484253\n",
            "Max accuracy for batch 491 = 0.75 at d = 0.8783320999145513\n",
            "Max accuracy for batch 492 = 0.5 at d = 1.1220474014282236\n",
            "Max accuracy for batch 493 = 0.6428571428571428 at d = 0.46635823678970356\n",
            "Max accuracy for batch 494 = 0.5 at d = 1.6156390538215644\n",
            "Max accuracy for batch 495 = 0.625 at d = 0.35324719548225403\n",
            "Max accuracy for batch 496 = 0.6666666666666666 at d = 0.7514178996086126\n",
            "Max accuracy for batch 497 = 0.5714285714285714 at d = 0.45190900564193726\n",
            "Max accuracy for batch 498 = 0.625 at d = 0.6357840714454653\n",
            "Max accuracy for batch 499 = 1.0 at d = 1.006099401235581\n",
            "Max accuracy for batch 500 = 0.8 at d = 0.9659836258888248\n",
            "Max accuracy for batch 501 = 0.6 at d = 0.87484531480074\n",
            "Max accuracy for batch 502 = 0.5666666666666667 at d = 1.1899143533706673\n",
            "Max accuracy for batch 503 = 0.8 at d = 0.38718950247764594\n",
            "Max accuracy for batch 504 = 0.9285714285714286 at d = 1.1829272882938393\n",
            "Max accuracy for batch 505 = 0.7 at d = 0.4526206383705139\n",
            "Max accuracy for batch 506 = 0.6333333333333333 at d = 0.4751370425224305\n",
            "Max accuracy for batch 507 = 0.7333333333333334 at d = 0.3765519587993622\n",
            "Max accuracy for batch 508 = 0.5333333333333333 at d = 0.7602282023429874\n",
            "Max accuracy for batch 509 = 0.6333333333333333 at d = 0.5929526189565663\n",
            "Max accuracy for batch 510 = 0.5 at d = 0.40108300304412847\n",
            "Max accuracy for batch 511 = 0.6666666666666666 at d = 0.3812953233718872\n",
            "Max accuracy for batch 512 = 0.75 at d = 0.2592112419605256\n",
            "Max accuracy for batch 513 = 0.6 at d = 0.49290433526039124\n",
            "Max accuracy for batch 514 = 0.6666666666666666 at d = 1.0595759821534165\n",
            "Max accuracy for batch 515 = 0.75 at d = 0.7659908628463747\n",
            "Max accuracy for batch 516 = 0.625 at d = 0.19675906002521515\n",
            "Max accuracy for batch 517 = 0.9 at d = 0.9327834181785587\n",
            "Max accuracy for batch 518 = 0.8 at d = 0.5429453322887423\n",
            "Max accuracy for batch 519 = 0.75 at d = 1.2672567578554164\n",
            "Max accuracy for batch 520 = 0.875 at d = 0.9591485412120825\n",
            "Max accuracy for batch 521 = 0.8 at d = 0.8476197524070747\n",
            "Max accuracy for batch 522 = 0.75 at d = 0.8489520952701572\n",
            "Max accuracy for batch 523 = 0.75 at d = 1.2102606470584876\n",
            "Max accuracy for batch 524 = 0.6666666666666666 at d = 1.3263678247928627\n",
            "Max accuracy for batch 525 = 0.5 at d = 1.2901181020736698\n",
            "Max accuracy for batch 526 = 0.7 at d = 1.3118567032814035\n",
            "Max accuracy for batch 527 = 0.7333333333333334 at d = 0.5100665954351429\n",
            "Max accuracy for batch 528 = 0.75 at d = 1.425365505695344\n",
            "Max accuracy for batch 529 = 0.5833333333333334 at d = 0.33134010434150696\n",
            "Max accuracy for batch 530 = 0.9166666666666667 at d = 0.4187540932893755\n",
            "Max accuracy for batch 531 = 0.6666666666666666 at d = 0.4680985012054445\n",
            "Max accuracy for batch 532 = 0.7333333333333334 at d = 0.9859050135612494\n",
            "Max accuracy for batch 533 = 0 at d = 0\n",
            "Max accuracy for batch 534 = 0.7 at d = 0.7674885556697848\n",
            "Max accuracy for batch 535 = 1.0 at d = 0.8598548662662511\n",
            "Max accuracy for batch 536 = 0.5 at d = 1.0871314969062813\n",
            "Max accuracy for batch 537 = 0.6666666666666667 at d = 0.7907812390327457\n",
            "Max accuracy for batch 538 = 0.6428571428571428 at d = 0.8028824760913854\n",
            "Max accuracy for batch 539 = 0.6428571428571428 at d = 0.4071903917789461\n",
            "Max accuracy for batch 540 = 0.5 at d = 0.3324468109607698\n",
            "Max accuracy for batch 541 = 0.5833333333333334 at d = 0.11937513202428818\n",
            "Max accuracy for batch 542 = 0.875 at d = 0.803675181627274\n",
            "Max accuracy for batch 543 = 0.5714285714285714 at d = 0.4196317791938782\n",
            "Max accuracy for batch 544 = 0.6333333333333333 at d = 0.6902056822776796\n",
            "Max accuracy for batch 545 = 0.9285714285714286 at d = 0.3514858493804932\n",
            "Max accuracy for batch 546 = 0.5833333333333334 at d = 1.280582619667054\n",
            "Max accuracy for batch 547 = 0.5 at d = 0.7356931456327443\n",
            "Max accuracy for batch 548 = 1.0 at d = 0.7923496706485754\n",
            "Max accuracy for batch 549 = 0.625 at d = 0.12871508300304413\n",
            "Max accuracy for batch 550 = 0.7857142857142857 at d = 0.8466736712455752\n",
            "Max accuracy for batch 551 = 0.6 at d = 0.3720057010650635\n",
            "Max accuracy for batch 552 = 0.8 at d = 0.9451154060363772\n",
            "Max accuracy for batch 553 = 0.5666666666666667 at d = 0.5137943940162659\n",
            "Max accuracy for batch 554 = 0.625 at d = 0.5677461624145508\n",
            "Max accuracy for batch 555 = 0.625 at d = 0.07510611414909363\n",
            "Max accuracy for batch 556 = 0.6 at d = 0.8463927899599081\n",
            "Max accuracy for batch 557 = 0.6666666666666667 at d = 0.621143805742264\n",
            "Max accuracy for batch 558 = 0.5666666666666667 at d = 1.1655155313014993\n",
            "Max accuracy for batch 559 = 0.6666666666666667 at d = 0.38855009043216726\n",
            "Max accuracy for batch 560 = 0.7 at d = 0.29246765625476856\n",
            "Max accuracy for batch 561 = 0.6666666666666667 at d = 0.4821007384061816\n",
            "Max accuracy for batch 562 = 0.9 at d = 0.6171259518861775\n",
            "Max accuracy for batch 563 = 1.0 at d = 0.17371036112308502\n",
            "Max accuracy for batch 564 = 0.5714285714285714 at d = 0.2619026005268097\n",
            "Max accuracy for batch 565 = 0.6 at d = 0.0808614045381546\n",
            "Max accuracy for batch 566 = 0.75 at d = 0.19426146149635315\n",
            "Max accuracy for batch 567 = 0.625 at d = 0.1227276548743248\n",
            "Max accuracy for batch 568 = 0.625 at d = 0.12937821447849274\n",
            "Max accuracy for batch 569 = 0.6333333333333333 at d = 0.8840823731422429\n",
            "Max accuracy for batch 570 = 0.75 at d = 0.7656458864212038\n",
            "Max accuracy for batch 571 = 0.6666666666666666 at d = 0.9233900763988501\n",
            "Max accuracy for batch 572 = 0.7 at d = 0.3935739753246309\n",
            "Max accuracy for batch 573 = 0.7 at d = 0.4811785759925843\n",
            "Max accuracy for batch 574 = 0.7333333333333334 at d = 0.5297220163345341\n",
            "Max accuracy for batch 575 = 0.6428571428571428 at d = 0.31764219594001775\n",
            "Max accuracy for batch 576 = 0.625 at d = 1.3774352617263803\n",
            "Max accuracy for batch 577 = 0.9 at d = 0.7464592822790151\n",
            "Max accuracy for batch 578 = 0.8333333333333333 at d = 1.1140547347068792\n",
            "Max accuracy for batch 579 = 0.8333333333333333 at d = 0.32268364596366894\n",
            "Max accuracy for batch 580 = 0.7 at d = 1.2436007504463205\n",
            "Max accuracy for batch 581 = 0.6 at d = 0.5220533013343811\n",
            "Max accuracy for batch 582 = 0.8 at d = 0.7701921763420108\n",
            "Max accuracy for batch 583 = 0.9166666666666667 at d = 0.48288872671127325\n",
            "Max accuracy for batch 584 = 0.75 at d = 0.2646128087043763\n",
            "Max accuracy for batch 585 = 0.7 at d = 0.7558295638561252\n",
            "Max accuracy for batch 586 = 0.7333333333333334 at d = 0.5246390008926396\n",
            "Max accuracy for batch 587 = 0.5 at d = 1.2055774414539344\n",
            "Max accuracy for batch 588 = 0.5 at d = 0.46319225072860726\n",
            "Max accuracy for batch 589 = 0.6666666666666667 at d = 0.33700855016708375\n",
            "Max accuracy for batch 590 = 0.9166666666666667 at d = 0.37326500964164744\n",
            "Max accuracy for batch 591 = 0.8333333333333333 at d = 0.31525037580728554\n",
            "Max accuracy for batch 592 = 0.6 at d = 0.992396904468537\n",
            "Max accuracy for batch 593 = 0.6428571428571428 at d = 0.27636544823646547\n",
            "Max accuracy for batch 594 = 0.5 at d = 1.1796424084454786\n",
            "Max accuracy for batch 595 = 0.7 at d = 1.1396500945091255\n",
            "Max accuracy for batch 596 = 0.5 at d = 1.0391605526208885\n",
            "Max accuracy for batch 597 = 0.9166666666666667 at d = 0.6380379881858826\n",
            "Max accuracy for batch 598 = 0.625 at d = 0.4159160852432251\n",
            "Max accuracy for batch 599 = 0.5 at d = 1.1315732746124274\n",
            "Max accuracy for batch 600 = 0.625 at d = 1.2834632551670084\n",
            "Max accuracy for batch 601 = 0.6333333333333333 at d = 0.46762829133868256\n",
            "Max accuracy for batch 602 = 0.5 at d = 1.3591960067749032\n",
            "Max accuracy for batch 603 = 0.7333333333333334 at d = 0.4126221565008166\n",
            "Max accuracy for batch 604 = 0.5666666666666667 at d = 0.4647602491974834\n",
            "Max accuracy for batch 605 = 0.7 at d = 0.9723223822116857\n",
            "Max accuracy for batch 606 = 0.7 at d = 0.9385556907653814\n",
            "Max accuracy for batch 607 = 0.625 at d = 0.29174503684043884\n",
            "Max accuracy for batch 608 = 0.7857142857142857 at d = 0.7226404845714574\n",
            "Max accuracy for batch 609 = 0.8 at d = 0.9422790846824651\n",
            "Max accuracy for batch 610 = 0.7333333333333334 at d = 0.9512096500396734\n",
            "Max accuracy for batch 611 = 0.5 at d = 0.4324875402450562\n",
            "Max accuracy for batch 612 = 0.5833333333333333 at d = 0.5442179059982302\n",
            "Max accuracy for batch 613 = 0.75 at d = 0.8157377018332488\n",
            "Max accuracy for batch 614 = 0.8333333333333333 at d = 0.5732329180836682\n",
            "Max accuracy for batch 615 = 0.5 at d = 1.3992098267078408\n",
            "Max accuracy for batch 616 = 0.7333333333333334 at d = 0.42666836094856275\n",
            "Max accuracy for batch 617 = 0.875 at d = 0.742222875475884\n",
            "Max accuracy for batch 618 = 0.5333333333333333 at d = 0.45086300641298327\n",
            "Max accuracy for batch 619 = 0.8333333333333333 at d = 0.7214249727725985\n",
            "Max accuracy for batch 620 = 0.6 at d = 1.2384161890745173\n",
            "Max accuracy for batch 621 = 0.8333333333333333 at d = 1.174673681974412\n",
            "Max accuracy for batch 622 = 0.7333333333333334 at d = 0.5409241008758547\n",
            "Max accuracy for batch 623 = 0.5833333333333334 at d = 1.4115575695037852\n",
            "Max accuracy for batch 624 = 0.625 at d = 0.39570972323417664\n",
            "Max accuracy for batch 625 = 0.6666666666666666 at d = 0.8593124284744268\n",
            "Max accuracy for batch 626 = 0.5 at d = 1.6508488757610333\n",
            "Max accuracy for batch 627 = 0.75 at d = 0.5521666774749757\n",
            "Max accuracy for batch 628 = 0.7333333333333334 at d = 0.6612727437019353\n",
            "Max accuracy for batch 629 = 0.5 at d = 0.7386760389804843\n",
            "Max accuracy for batch 630 = 0.5 at d = 0.3629148068428041\n",
            "Max accuracy for batch 631 = 0.7333333333333334 at d = 1.1028821198940284\n",
            "Max accuracy for batch 632 = 0.6333333333333333 at d = 0.41982851243019137\n",
            "Max accuracy for batch 633 = 0.7 at d = 0.9026275473237045\n",
            "Max accuracy for batch 634 = 0.625 at d = 0.7414933757781985\n",
            "Max accuracy for batch 635 = 0.7333333333333334 at d = 0.6168550276756287\n",
            "Max accuracy for batch 636 = 0.75 at d = 1.0677042977809912\n",
            "Max accuracy for batch 637 = 0.6666666666666666 at d = 0.8206615606546408\n",
            "Max accuracy for batch 638 = 0.6666666666666666 at d = 0.9497573347091682\n",
            "Max accuracy for batch 639 = 0.625 at d = 0.6627278827428822\n",
            "Max accuracy for batch 640 = 0.75 at d = 0.3549855351448059\n",
            "Max accuracy for batch 641 = 0 at d = 0\n",
            "Max accuracy for batch 642 = 0.875 at d = 0.39336129975318923\n",
            "Max accuracy for batch 643 = 0.5 at d = 1.3760448653697979\n",
            "Max accuracy for batch 644 = 0.6333333333333333 at d = 0.5747174084186556\n",
            "Max accuracy for batch 645 = 0.5 at d = 0.8119122604131704\n",
            "Max accuracy for batch 646 = 0.5333333333333333 at d = 1.2529336869716654\n",
            "Max accuracy for batch 647 = 0.5833333333333334 at d = 0.17411066591739655\n",
            "Max accuracy for batch 648 = 0.8 at d = 0.6619398150444034\n",
            "Max accuracy for batch 649 = 0.8333333333333333 at d = 0.5213425683975222\n",
            "Max accuracy for batch 650 = 0.7 at d = 0.6391450710296632\n",
            "Max accuracy for batch 651 = 0.5833333333333334 at d = 0.39575904607772827\n",
            "Max accuracy for batch 652 = 0.7857142857142857 at d = 0.572011819124222\n",
            "Max accuracy for batch 653 = 0.5333333333333333 at d = 0.7057822310924532\n",
            "Max accuracy for batch 654 = 0.9285714285714286 at d = 0.3789543571472168\n",
            "Max accuracy for batch 655 = 0.7 at d = 0.4172314099073412\n",
            "Max accuracy for batch 656 = 0.5833333333333334 at d = 0.4077474772930145\n",
            "Max accuracy for batch 657 = 0.625 at d = 0.18947890400886536\n",
            "Max accuracy for batch 658 = 0.75 at d = 0.28832969820499443\n",
            "Max accuracy for batch 659 = 0.5 at d = 1.2115423134565364\n",
            "Max accuracy for batch 660 = 0.8 at d = 0.6752409446239473\n",
            "Max accuracy for batch 661 = 0.5 at d = 1.6205225119590767\n",
            "Max accuracy for batch 662 = 0.5 at d = 1.220066854715348\n",
            "Max accuracy for batch 663 = 0.625 at d = 0.9695458047389989\n",
            "Max accuracy for batch 664 = 0.5 at d = 1.9066129666566864\n",
            "Max accuracy for batch 665 = 0.8333333333333333 at d = 0.9757426805496219\n",
            "Max accuracy for batch 666 = 0.75 at d = 0.4119015038013458\n",
            "Max accuracy for batch 667 = 0.5666666666666667 at d = 0.3507589371204377\n",
            "Max accuracy for batch 668 = 0.75 at d = 1.0088625420331963\n",
            "Max accuracy for batch 669 = 0.9 at d = 0.8245843786001211\n",
            "Max accuracy for batch 670 = 0.5 at d = 1.2094842572212228\n",
            "Max accuracy for batch 671 = 0.5666666666666667 at d = 0.5573581621646885\n",
            "Max accuracy for batch 672 = 0.5 at d = 1.0258337628841407\n",
            "Max accuracy for batch 673 = 0.6428571428571428 at d = 0.5751126830577854\n",
            "Max accuracy for batch 674 = 0.875 at d = 0.5194515025615694\n",
            "Max accuracy for batch 675 = 0.5666666666666667 at d = 0.953517588615418\n",
            "Max accuracy for batch 676 = 0.8333333333333333 at d = 0.5513633403778078\n",
            "Max accuracy for batch 677 = 0.8 at d = 0.3651967955827714\n",
            "Max accuracy for batch 678 = 0.5 at d = 1.6625576506257072\n",
            "Max accuracy for batch 679 = 0.625 at d = 0.3474976718425751\n",
            "Max accuracy for batch 680 = 0.6666666666666666 at d = 1.1895557396411904\n",
            "Max accuracy for batch 681 = 0.5666666666666667 at d = 0.9658377790451056\n",
            "Max accuracy for batch 682 = 0.5833333333333333 at d = 0.6129825329780582\n",
            "Max accuracy for batch 683 = 0.75 at d = 0.6867135047912599\n",
            "Max accuracy for batch 684 = 0.5 at d = 0.46093910098075885\n",
            "Max accuracy for batch 685 = 0.8333333333333333 at d = 0.644234973907471\n",
            "Max accuracy for batch 686 = 1.0 at d = 0.9955288279056554\n",
            "Max accuracy for batch 687 = 0.5 at d = 1.757817778825761\n",
            "Max accuracy for batch 688 = 0.5 at d = 1.6611973381042493\n",
            "Max accuracy for batch 689 = 0.875 at d = 0.4182523000240328\n",
            "Max accuracy for batch 690 = 0.5 at d = 1.5062156443595895\n",
            "Max accuracy for batch 691 = 0.9166666666666667 at d = 0.34291124594211597\n",
            "Max accuracy for batch 692 = 0.7333333333333334 at d = 0.49323853874206547\n",
            "Max accuracy for batch 693 = 0.5 at d = 1.232253599882127\n",
            "Max accuracy for batch 694 = 0.5833333333333334 at d = 1.2596618703603752\n",
            "Max accuracy for batch 695 = 0.7 at d = 0.10018191760778428\n",
            "Max accuracy for batch 696 = 0.5 at d = 1.2464495706558234\n",
            "Max accuracy for batch 697 = 0.875 at d = 0.8838787531852725\n",
            "Max accuracy for batch 698 = 0.8333333333333333 at d = 0.931115792751313\n",
            "Max accuracy for batch 699 = 0.7 at d = 0.4205927199125292\n",
            "Max accuracy for batch 700 = 0.6333333333333333 at d = 0.9635150499343877\n",
            "Max accuracy for batch 701 = 0.75 at d = 0.6378497878313069\n",
            "Max accuracy for batch 702 = 0.7333333333333334 at d = 0.263534695506096\n",
            "Max accuracy for batch 703 = 0.75 at d = 0.9665915753841405\n",
            "Max accuracy for batch 704 = 0.5 at d = 1.4077823181152351\n",
            "Max accuracy for batch 705 = 0.8 at d = 0.6137275660037996\n",
            "Max accuracy for batch 706 = 0.6 at d = 0.747325672268868\n",
            "Max accuracy for batch 707 = 0.625 at d = 0.04856031388044357\n",
            "Max accuracy for batch 708 = 0.6 at d = 0.1944015473127365\n",
            "Max accuracy for batch 709 = 0.625 at d = 1.1446264349222193\n",
            "Max accuracy for batch 710 = 0.625 at d = 0.16812965273857117\n",
            "Max accuracy for batch 711 = 0.625 at d = 0.6466947176456453\n",
            "Max accuracy for batch 712 = 0.7 at d = 0.6003624746799473\n",
            "Max accuracy for batch 713 = 0.5 at d = 1.0762567622661596\n",
            "Max accuracy for batch 714 = 0.875 at d = 0.3688807849884034\n",
            "Max accuracy for batch 715 = 1.0 at d = 0.6215086988955741\n",
            "Max accuracy for batch 716 = 1.0 at d = 0.6000076631307606\n",
            "Max accuracy for batch 717 = 0.5 at d = 1.2231639785766606\n",
            "Max accuracy for batch 718 = 0 at d = 0\n",
            "0.0\n"
          ]
        }
      ],
      "source": [
        "test_dataset = SiameseDataset(\n",
        "    training_csv=testing_csv,\n",
        "    training_dir=testing_dir,\n",
        "    transform=transforms.Compose(\n",
        "        [transforms.Resize((105, 105)), transforms.ToTensor()]\n",
        "    ),\n",
        ")\n",
        "\n",
        "batch_avg_acc = 0 # initialize the batch average accuracy\n",
        "batch_avg_d = 0 # initialize the batch average distance\n",
        "n_batch = 0 # initialize the number of batches\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset, num_workers=6, batch_size=8, shuffle=True)\n",
        "\n",
        "total_count = 0 # initialize the total count\n",
        "correct_count=0 # initialize the correct count\n",
        "d_acc=0 # initialize the distance accuracy\n",
        "# threshold=0.6\n",
        "for i, data in enumerate(test_dataloader, 0):\n",
        "    x0, x1, label = data\n",
        "    concat = torch.cat((x0, x1), 0)\n",
        "    output1, output2 = model(x0, x1)\n",
        "    labels=label.long()\n",
        "    eucledian_distance = F.pairwise_distance(output1, output2)\n",
        "    total_count += 1\n",
        "    # if label == torch.FloatTensor([[0]]):\n",
        "    #     label = \"Original Pair Of Signature\"\n",
        "    # else:\n",
        "    #     label = \"Forged Pair Of Signature\"\n",
        "    acc, d = compute_accuracy_roc(eucledian_distance.detach().numpy(), labels.detach().numpy())\n",
        "    # acc, d = compute_accuracy_roc(dist.detach().numpy(), labels.detach().numpy())\n",
        "    print('Max accuracy for batch {} = {} at d = {}'.format(i, acc, d))\n",
        "    batch_avg_acc += acc\n",
        "    batch_avg_d += d\n",
        "    n_batch += 1\n",
        "\n",
        "    # imshow(torchvision.utils.make_grid(concat))\n",
        "    # print(\"Predicted Eucledian Distance:-\", eucledian_distance.item())\n",
        "    # print(\"Actual Label:-\", label)\n",
        "\n",
        "#     if eucledian_distance.item() < threshold:\n",
        "#         predicted_label = \"Original Pair Of Signature\"\n",
        "#     else:\n",
        "#         predicted_label = \"Forged Pair Of Signature\"\n",
        "\n",
        "#     if predicted_label == label:\n",
        "#         correct_count += 1\n",
        "\n",
        "#     total_count += 1\n",
        "\n",
        "#     imshow(torchvision.utils.make_grid(concat))\n",
        "#     print(\"Predicted Label:-\", predicted_label)\n",
        "#     print(\"Actual Label:-\", label)\n",
        "#     print(\"Predicted Eucledian Distance:-\", eucledian_distance.item())\n",
        "\n",
        "\n",
        "# accuracy = correct_count / total_count\n",
        "# print(\"Accuracy:-\", accuracy)\n",
        "print(d_acc/10);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_OQ9jQOVW5j",
        "outputId": "c3d32f4c-16ae-477e-ba06-2110c4f4e2e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg acc across all batches=0.6711868335651373 at d=0.6940036735244833\n"
          ]
        }
      ],
      "source": [
        "print('Avg acc across all batches={} at d={}'.format(batch_avg_acc / n_batch, batch_avg_d / n_batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BntXQKnASThf"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def compute_accuracy_roc(predictions, labels):\n",
        "    dmax = np.max(predictions) # maximum distance between the two embeddings\n",
        "    dmin = np.min(predictions) # minimum distance between the two embeddings\n",
        "    nsame = np.sum(labels == 1) # number of similar image pairs\n",
        "    ndiff = np.sum(labels == 0) # number of dissimilar image pairs\n",
        "    step = 0.001 # step size\n",
        "    max_acc = 0 # initialize the maximum accuracy\n",
        "\n",
        "    d_optimal = 0 # initialize the optimal distance\n",
        "    for d in np.arange(dmin, dmax + step, step):\n",
        "        idx1 = predictions.ravel() <= d # ravel() is used to flatten the array and idx1 is used to store the indices of the predictions that are less than or equal to d \n",
        "        idx2 = predictions.ravel() > d # idx2 is used to store the indices of the predictions that are greater than d\n",
        "\n",
        "        tpr = float(np.sum(labels[idx1] == 1)) / nsame  \n",
        "        tnr = float(np.sum(labels[idx2] == 0)) / ndiff\n",
        "\n",
        "        acc = 0.5 * (tpr + tnr)\n",
        "\n",
        "        if acc > max_acc:\n",
        "            max_acc = acc\n",
        "            d_optimal = d\n",
        "\n",
        "    return max_acc, d_optimal\n",
        "\n",
        "\n",
        "batch_avg_acc = 0\n",
        "batch_avg_d = 0\n",
        "n_batch = 0\n",
        "\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    global batch_avg_acc, batch_avg_d, n_batch\n",
        "\n",
        "    test_dataset = TestDataset()\n",
        "    loader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "    for batch_index, data in enumerate(loader):\n",
        "        A = data[0]\n",
        "        B = data[1]\n",
        "        labels = data[2].long()\n",
        "\n",
        "        f_a, f_b = model.forward(A, B)\n",
        "        dist = distance_metric(f_a, f_b)\n",
        "\n",
        "        acc, d = compute_accuracy_roc(dist.detach().numpy(), labels.detach().numpy())\n",
        "        print('Max accuracy for batch {} = {} at d = {}'.format(batch_index, acc, d))\n",
        "        batch_avg_acc += acc\n",
        "        batch_avg_d += d\n",
        "        n_batch += 1\n",
        "\n",
        "\n",
        "print('CEDAR1:')\n",
        "test()\n",
        "print('Avg acc across all batches={} at d={}'.format(batch_avg_acc / n_batch, batch_avg_d / n_batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f58HIHdcd0MB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
